{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The data we will use can be found [here](https://cogcomp.seas.upenn.edu/Data/QA/QC/). The dataset comprises three variables: `question`, `category`, and `sub-category`. However, our analysis will only use two variables: `question` and `category`. Essentially, we will build a model that uses the content of the question to predict its category. For example, (e.g. Who was Abraham Lincon?) and the output or label would be Human. There are six disnnct categories in the dataset:\n",
    "\n",
    "1. ENTY (Entity): Questions that seek specific entities as answers, like objects, organisms, or concepts.\n",
    "2. HUM (Human): Questions about humans, individually or as a group.\n",
    "3. DESC (Description): Questions asking for description, explanations, or reasons.\n",
    "4. Num (Numeric): Questions expecting numerical answer.\n",
    "4. LOC (Locanon): Questions that are geographically oriented.\n",
    "6. ABBR (Abbreviation): Questions seeking the extended form or explanation of abbreviations.\n",
    "\n",
    "For this work, we will use the Training Set 5 dataset for training the model and the single test set available for testing the model.\n",
    "\n",
    "We will now create the data download utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'data'\n",
    "os.makedirs(dir_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(dir_name: str, filename: str, url: str, expected_bytes: Optional[int]=None) -> str:\n",
    "    \"\"\"\n",
    "    Download a file if not present, and make sure it's the right size if the expected size is provided.\n",
    "    \n",
    "    Args:\n",
    "        dir_name (str): The directory where the data will be stored.\n",
    "        filename (str): The filename under which the data will be stored.\n",
    "        url (str): The URL from which to download the data.\n",
    "        expected_bytes (Optional[int]): The expected size of the data in bytes. \n",
    "                                        If provided, the function will check if the downloaded file size matches this.\n",
    "                                        If not, an exception will be raised.\n",
    "                                        If not provided, no size check will be performed.\n",
    "                                        \n",
    "    Returns:\n",
    "        str: The file path where the data is stored.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the directory if it doesn't already exist\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    filepath = os.path.join(dir_name, filename)\n",
    "\n",
    "    # Download the file if it doesn't already exist\n",
    "    if not os.path.exists(filepath):\n",
    "        response = requests.get(url)\n",
    "        with open(filepath, 'wb') as f:\n",
    "            # Write the content of the response to a file in the directory\n",
    "            f.write(response.content)\n",
    "\n",
    "    # If an expected size is provided, verify the size of the downloaded file\n",
    "    if expected_bytes is not None:   \n",
    "        statinfo = os.stat(filepath)\n",
    "        if statinfo.st_size == expected_bytes:\n",
    "            print(f'Found and verified {filepath}')\n",
    "        else:\n",
    "            print(f'File size {statinfo.st_size} does not match expected size {expected_bytes}')\n",
    "            raise Exception(\n",
    "              f'Failed to verify {filepath}. Can you get to it with a browser?')\n",
    "    \n",
    "    # Return the filepath for use elsewhere\n",
    "    return filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data.\n",
    "url = 'http://cogcomp.org/Data/QA/QC/'\n",
    "dir_name = 'data'\n",
    "train_filename = download_data(dir_name, 'train_5500.label', url+'train_5500.label', 335858)\n",
    "test_filename = download_data(dir_name, 'TREC_10.label', url+'TREC_10.label', 23354)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
